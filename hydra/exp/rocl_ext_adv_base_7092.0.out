=> Reading YAML config from configs/configs.yml
#################### Pre-training network ####################
===>>  gradient for importance_scores: None  | training weights only
Initialization relevance score with None initialization
Files already downloaded and verified
Files already downloaded and verified
Traing loader: 50000 images, Test loader: 10000 images
Missing in RoCL, total=23, {'layer2.1.conv2.popup_scores', 'layer4.1.conv1.popup_scores', 'layer3.0.conv1.popup_scores', 'layer1.1.conv2.popup_scores', 'layer2.1.conv1.popup_scores', 'layer4.1.conv2.popup_scores', 'layer3.0.conv2.popup_scores', 'linear.popup_scores', 'layer2.0.conv2.popup_scores', 'conv1.popup_scores', 'layer4.0.shortcut.0.popup_scores', 'layer3.1.conv2.popup_scores', 'linear.weight', 'layer1.0.conv1.popup_scores', 'layer3.1.conv1.popup_scores', 'layer3.0.shortcut.0.popup_scores', 'layer4.0.conv2.popup_scores', 'layer1.0.conv2.popup_scores', 'layer4.0.conv1.popup_scores', 'layer2.0.conv1.popup_scores', 'linear.bias', 'layer1.1.conv1.popup_scores', 'layer2.0.shortcut.0.popup_scores'}
variable = conv1.weight, Gradient requires_grad = True
variable = conv1.popup_scores, Gradient requires_grad = False
variable = bn1.weight, Gradient requires_grad = True
variable = bn1.bias, Gradient requires_grad = True
variable = layer1.0.conv1.weight, Gradient requires_grad = True
variable = layer1.0.conv1.popup_scores, Gradient requires_grad = False
variable = layer1.0.bn1.weight, Gradient requires_grad = True
variable = layer1.0.bn1.bias, Gradient requires_grad = True
variable = layer1.0.conv2.weight, Gradient requires_grad = True
variable = layer1.0.conv2.popup_scores, Gradient requires_grad = False
variable = layer1.0.bn2.weight, Gradient requires_grad = True
variable = layer1.0.bn2.bias, Gradient requires_grad = True
variable = layer1.1.conv1.weight, Gradient requires_grad = True
variable = layer1.1.conv1.popup_scores, Gradient requires_grad = False
variable = layer1.1.bn1.weight, Gradient requires_grad = True
variable = layer1.1.bn1.bias, Gradient requires_grad = True
variable = layer1.1.conv2.weight, Gradient requires_grad = True
variable = layer1.1.conv2.popup_scores, Gradient requires_grad = False
variable = layer1.1.bn2.weight, Gradient requires_grad = True
variable = layer1.1.bn2.bias, Gradient requires_grad = True
variable = layer2.0.conv1.weight, Gradient requires_grad = True
variable = layer2.0.conv1.popup_scores, Gradient requires_grad = False
variable = layer2.0.bn1.weight, Gradient requires_grad = True
variable = layer2.0.bn1.bias, Gradient requires_grad = True
variable = layer2.0.conv2.weight, Gradient requires_grad = True
variable = layer2.0.conv2.popup_scores, Gradient requires_grad = False
variable = layer2.0.bn2.weight, Gradient requires_grad = True
variable = layer2.0.bn2.bias, Gradient requires_grad = True
variable = layer2.0.shortcut.0.weight, Gradient requires_grad = True
variable = layer2.0.shortcut.0.popup_scores, Gradient requires_grad = False
variable = layer2.0.shortcut.1.weight, Gradient requires_grad = True
variable = layer2.0.shortcut.1.bias, Gradient requires_grad = True
variable = layer2.1.conv1.weight, Gradient requires_grad = True
variable = layer2.1.conv1.popup_scores, Gradient requires_grad = False
variable = layer2.1.bn1.weight, Gradient requires_grad = True
variable = layer2.1.bn1.bias, Gradient requires_grad = True
variable = layer2.1.conv2.weight, Gradient requires_grad = True
variable = layer2.1.conv2.popup_scores, Gradient requires_grad = False
variable = layer2.1.bn2.weight, Gradient requires_grad = True
variable = layer2.1.bn2.bias, Gradient requires_grad = True
variable = layer3.0.conv1.weight, Gradient requires_grad = True
variable = layer3.0.conv1.popup_scores, Gradient requires_grad = False
variable = layer3.0.bn1.weight, Gradient requires_grad = True
variable = layer3.0.bn1.bias, Gradient requires_grad = True
variable = layer3.0.conv2.weight, Gradient requires_grad = True
variable = layer3.0.conv2.popup_scores, Gradient requires_grad = False
variable = layer3.0.bn2.weight, Gradient requires_grad = True
variable = layer3.0.bn2.bias, Gradient requires_grad = True
variable = layer3.0.shortcut.0.weight, Gradient requires_grad = True
variable = layer3.0.shortcut.0.popup_scores, Gradient requires_grad = False
variable = layer3.0.shortcut.1.weight, Gradient requires_grad = True
variable = layer3.0.shortcut.1.bias, Gradient requires_grad = True
variable = layer3.1.conv1.weight, Gradient requires_grad = True
variable = layer3.1.conv1.popup_scores, Gradient requires_grad = False
variable = layer3.1.bn1.weight, Gradient requires_grad = True
variable = layer3.1.bn1.bias, Gradient requires_grad = True
variable = layer3.1.conv2.weight, Gradient requires_grad = True
variable = layer3.1.conv2.popup_scores, Gradient requires_grad = False
variable = layer3.1.bn2.weight, Gradient requires_grad = True
variable = layer3.1.bn2.bias, Gradient requires_grad = True
variable = layer4.0.conv1.weight, Gradient requires_grad = True
variable = layer4.0.conv1.popup_scores, Gradient requires_grad = False
variable = layer4.0.bn1.weight, Gradient requires_grad = True
variable = layer4.0.bn1.bias, Gradient requires_grad = True
variable = layer4.0.conv2.weight, Gradient requires_grad = True
variable = layer4.0.conv2.popup_scores, Gradient requires_grad = False
variable = layer4.0.bn2.weight, Gradient requires_grad = True
variable = layer4.0.bn2.bias, Gradient requires_grad = True
variable = layer4.0.shortcut.0.weight, Gradient requires_grad = True
variable = layer4.0.shortcut.0.popup_scores, Gradient requires_grad = False
variable = layer4.0.shortcut.1.weight, Gradient requires_grad = True
variable = layer4.0.shortcut.1.bias, Gradient requires_grad = True
variable = layer4.1.conv1.weight, Gradient requires_grad = True
variable = layer4.1.conv1.popup_scores, Gradient requires_grad = False
variable = layer4.1.bn1.weight, Gradient requires_grad = True
variable = layer4.1.bn1.bias, Gradient requires_grad = True
variable = layer4.1.conv2.weight, Gradient requires_grad = True
variable = layer4.1.conv2.popup_scores, Gradient requires_grad = False
variable = layer4.1.bn2.weight, Gradient requires_grad = True
variable = layer4.1.bn2.bias, Gradient requires_grad = True
variable = linear.weight, Gradient requires_grad = True
variable = linear.bias, Gradient requires_grad = True
variable = linear.popup_scores, Gradient requires_grad = False
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09961
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [0][  0/196]	Time  3.795 ( 3.795)	Data  0.000 ( 0.000)	Loss 2.3895 (2.3895)	Acc_1   6.64 (  6.64)	Acc_5  40.23 ( 40.23)
Epoch: [0][100/196]	Time  3.697 ( 3.701)	Data  0.000 ( 0.000)	Loss 1.6298 (1.6983)	Acc_1  61.33 ( 55.73)	Acc_5  94.53 ( 93.03)
Test: [39/40]	Time  0.547 ( 2.303)	Loss 1.0446 (1.1691)	Adv_Loss 1.4797 (1.6215)	Acc_1  68.75 ( 65.16)	Acc_5 100.00 ( 96.27)	Adv-Acc_1  37.50 ( 40.67)	Adv-Acc_5  93.75 ( 88.19)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.10000
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [1][  0/196]	Time  3.476 ( 3.476)	Data  0.000 ( 0.000)	Loss 1.4534 (1.4534)	Acc_1  62.11 ( 62.11)	Acc_5  97.66 ( 97.66)
Epoch: [1][100/196]	Time  3.676 ( 3.677)	Data  0.000 ( 0.000)	Loss 1.4449 (1.4772)	Acc_1  68.36 ( 66.25)	Acc_5  98.05 ( 96.64)
Test: [39/40]	Time  0.532 ( 2.294)	Loss 0.9339 (1.0994)	Adv_Loss 1.3592 (1.5498)	Acc_1  62.50 ( 69.86)	Acc_5 100.00 ( 97.49)	Adv-Acc_1  37.50 ( 42.69)	Adv-Acc_5 100.00 ( 90.32)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09961
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [2][  0/196]	Time  3.483 ( 3.483)	Data  0.000 ( 0.000)	Loss 1.3637 (1.3637)	Acc_1  73.05 ( 73.05)	Acc_5  97.27 ( 97.27)
Epoch: [2][100/196]	Time  3.676 ( 3.677)	Data  0.000 ( 0.000)	Loss 1.5148 (1.4208)	Acc_1  66.41 ( 68.70)	Acc_5  95.70 ( 97.29)
Test: [39/40]	Time  0.533 ( 2.294)	Loss 0.9230 (1.0724)	Adv_Loss 1.3427 (1.5244)	Acc_1  81.25 ( 70.16)	Acc_5 100.00 ( 97.53)	Adv-Acc_1  31.25 ( 43.40)	Adv-Acc_5 100.00 ( 90.51)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09843
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [3][  0/196]	Time  3.443 ( 3.443)	Data  0.000 ( 0.000)	Loss 1.3667 (1.3667)	Acc_1  72.66 ( 72.66)	Acc_5  97.27 ( 97.27)
Epoch: [3][100/196]	Time  3.700 ( 3.689)	Data  0.000 ( 0.000)	Loss 1.3638 (1.3912)	Acc_1  75.00 ( 69.88)	Acc_5  96.09 ( 97.54)
Test: [39/40]	Time  0.549 ( 2.309)	Loss 0.8757 (1.0345)	Adv_Loss 1.3043 (1.4930)	Acc_1  87.50 ( 72.22)	Acc_5 100.00 ( 97.97)	Adv-Acc_1  43.75 ( 44.86)	Adv-Acc_5 100.00 ( 90.99)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09649
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [4][  0/196]	Time  3.517 ( 3.517)	Data  0.000 ( 0.000)	Loss 1.3994 (1.3994)	Acc_1  69.53 ( 69.53)	Acc_5  96.09 ( 96.09)
Epoch: [4][100/196]	Time  3.696 ( 3.699)	Data  0.000 ( 0.000)	Loss 1.3513 (1.3676)	Acc_1  71.48 ( 71.17)	Acc_5  96.88 ( 97.66)
Test: [39/40]	Time  0.547 ( 2.305)	Loss 0.8884 (1.0400)	Adv_Loss 1.2970 (1.4974)	Acc_1  75.00 ( 71.43)	Acc_5 100.00 ( 98.07)	Adv-Acc_1  56.25 ( 44.44)	Adv-Acc_5 100.00 ( 91.20)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09382
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [5][  0/196]	Time  3.464 ( 3.464)	Data  0.000 ( 0.000)	Loss 1.3907 (1.3907)	Acc_1  73.83 ( 73.83)	Acc_5  98.05 ( 98.05)
Epoch: [5][100/196]	Time  3.694 ( 3.695)	Data  0.000 ( 0.000)	Loss 1.3289 (1.3490)	Acc_1  71.09 ( 71.95)	Acc_5  97.66 ( 97.73)
Test: [39/40]	Time  0.552 ( 2.306)	Loss 0.8911 (1.0407)	Adv_Loss 1.3014 (1.4885)	Acc_1  68.75 ( 72.08)	Acc_5 100.00 ( 98.02)	Adv-Acc_1  43.75 ( 44.66)	Adv-Acc_5 100.00 ( 91.86)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09045
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [6][  0/196]	Time  3.507 ( 3.507)	Data  0.000 ( 0.000)	Loss 1.2913 (1.2913)	Acc_1  76.56 ( 76.56)	Acc_5  98.44 ( 98.44)
Epoch: [6][100/196]	Time  3.699 ( 3.697)	Data  0.000 ( 0.000)	Loss 1.3277 (1.3260)	Acc_1  71.88 ( 73.40)	Acc_5  98.83 ( 97.94)
Test: [39/40]	Time  0.552 ( 2.309)	Loss 0.8554 (1.0059)	Adv_Loss 1.2717 (1.4656)	Acc_1  81.25 ( 72.77)	Acc_5 100.00 ( 98.14)	Adv-Acc_1  37.50 ( 45.24)	Adv-Acc_5 100.00 ( 91.84)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.08645
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [7][  0/196]	Time  3.471 ( 3.471)	Data  0.000 ( 0.000)	Loss 1.2753 (1.2753)	Acc_1  78.12 ( 78.12)	Acc_5  99.61 ( 99.61)
Epoch: [7][100/196]	Time  3.701 ( 3.702)	Data  0.000 ( 0.000)	Loss 1.3300 (1.3105)	Acc_1  75.78 ( 74.30)	Acc_5  96.88 ( 98.22)
Test: [39/40]	Time  0.559 ( 2.309)	Loss 0.8734 (0.9927)	Adv_Loss 1.2985 (1.4552)	Acc_1  87.50 ( 73.36)	Acc_5 100.00 ( 98.04)	Adv-Acc_1  37.50 ( 46.16)	Adv-Acc_5 100.00 ( 91.52)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.08187
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [8][  0/196]	Time  3.516 ( 3.516)	Data  0.000 ( 0.000)	Loss 1.2995 (1.2995)	Acc_1  71.88 ( 71.88)	Acc_5  97.27 ( 97.27)
Epoch: [8][100/196]	Time  3.698 ( 3.700)	Data  0.000 ( 0.000)	Loss 1.3388 (1.2972)	Acc_1  74.22 ( 74.68)	Acc_5  97.66 ( 98.13)
Test: [39/40]	Time  0.572 ( 2.310)	Loss 0.8871 (0.9867)	Adv_Loss 1.3040 (1.4527)	Acc_1  87.50 ( 73.39)	Acc_5 100.00 ( 97.95)	Adv-Acc_1  43.75 ( 46.48)	Adv-Acc_5 100.00 ( 91.81)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.07679
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [9][  0/196]	Time  3.560 ( 3.560)	Data  0.000 ( 0.000)	Loss 1.2615 (1.2615)	Acc_1  75.78 ( 75.78)	Acc_5  98.44 ( 98.44)
Epoch: [9][100/196]	Time  3.706 ( 3.703)	Data  0.000 ( 0.000)	Loss 1.3769 (1.2879)	Acc_1  71.09 ( 75.14)	Acc_5  97.27 ( 98.36)
Test: [39/40]	Time  0.552 ( 2.310)	Loss 0.8406 (0.9767)	Adv_Loss 1.2571 (1.4474)	Acc_1  81.25 ( 73.85)	Acc_5 100.00 ( 98.06)	Adv-Acc_1  43.75 ( 46.51)	Adv-Acc_5  93.75 ( 91.81)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.07129
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [10][  0/196]	Time  3.514 ( 3.514)	Data  0.000 ( 0.000)	Loss 1.2669 (1.2669)	Acc_1  75.78 ( 75.78)	Acc_5  98.83 ( 98.83)
Epoch: [10][100/196]	Time  3.699 ( 3.701)	Data  0.000 ( 0.000)	Loss 1.3790 (1.2747)	Acc_1  74.61 ( 75.83)	Acc_5  97.66 ( 98.29)
Test: [39/40]	Time  0.554 ( 2.310)	Loss 0.7749 (0.9471)	Adv_Loss 1.1847 (1.4277)	Acc_1  87.50 ( 74.92)	Acc_5 100.00 ( 98.41)	Adv-Acc_1  56.25 ( 47.42)	Adv-Acc_5 100.00 ( 92.18)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.06545
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [11][  0/196]	Time  3.562 ( 3.562)	Data  0.000 ( 0.000)	Loss 1.1907 (1.1907)	Acc_1  79.30 ( 79.30)	Acc_5  99.22 ( 99.22)
Epoch: [11][100/196]	Time  3.710 ( 3.702)	Data  0.000 ( 0.000)	Loss 1.3237 (1.2590)	Acc_1  74.22 ( 76.96)	Acc_5  99.22 ( 98.49)
Test: [39/40]	Time  0.560 ( 2.310)	Loss 0.8177 (0.9706)	Adv_Loss 1.2054 (1.4358)	Acc_1  81.25 ( 74.59)	Acc_5 100.00 ( 98.34)	Adv-Acc_1  50.00 ( 47.03)	Adv-Acc_5 100.00 ( 92.44)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.05937
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [12][  0/196]	Time  3.514 ( 3.514)	Data  0.000 ( 0.000)	Loss 1.1988 (1.1988)	Acc_1  78.52 ( 78.52)	Acc_5  99.22 ( 99.22)
Epoch: [12][100/196]	Time  3.708 ( 3.709)	Data  0.000 ( 0.000)	Loss 1.2109 (1.2526)	Acc_1  78.52 ( 77.19)	Acc_5  98.44 ( 98.57)
Test: [39/40]	Time  0.557 ( 2.311)	Loss 0.8269 (0.9734)	Adv_Loss 1.2042 (1.4274)	Acc_1  81.25 ( 74.94)	Acc_5 100.00 ( 98.35)	Adv-Acc_1  56.25 ( 47.57)	Adv-Acc_5 100.00 ( 92.20)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.05314
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [13][  0/196]	Time  3.525 ( 3.525)	Data  0.000 ( 0.000)	Loss 1.2281 (1.2281)	Acc_1  74.61 ( 74.61)	Acc_5  99.61 ( 99.61)
Epoch: [13][100/196]	Time  3.707 ( 3.702)	Data  0.000 ( 0.000)	Loss 1.2216 (1.2465)	Acc_1  75.78 ( 77.48)	Acc_5  99.22 ( 98.58)
Test: [39/40]	Time  0.559 ( 2.311)	Loss 0.7919 (0.9521)	Adv_Loss 1.1844 (1.4261)	Acc_1  87.50 ( 74.91)	Acc_5 100.00 ( 98.38)	Adv-Acc_1  43.75 ( 47.36)	Adv-Acc_5 100.00 ( 92.21)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.04686
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [14][  0/196]	Time  3.472 ( 3.472)	Data  0.000 ( 0.000)	Loss 1.2303 (1.2303)	Acc_1  79.30 ( 79.30)	Acc_5  99.61 ( 99.61)
Epoch: [14][100/196]	Time  3.705 ( 3.704)	Data  0.000 ( 0.000)	Loss 1.2177 (1.2281)	Acc_1  77.34 ( 78.37)	Acc_5  98.83 ( 98.72)
Test: [39/40]	Time  0.534 ( 2.297)	Loss 0.7624 (0.9490)	Adv_Loss 1.1526 (1.4189)	Acc_1  87.50 ( 75.47)	Acc_5 100.00 ( 98.37)	Adv-Acc_1  50.00 ( 47.45)	Adv-Acc_5 100.00 ( 92.16)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.04063
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [15][  0/196]	Time  3.482 ( 3.482)	Data  0.000 ( 0.000)	Loss 1.1394 (1.1394)	Acc_1  78.91 ( 78.91)	Acc_5  99.22 ( 99.22)
Epoch: [15][100/196]	Time  3.674 ( 3.676)	Data  0.000 ( 0.000)	Loss 1.2725 (1.2264)	Acc_1  75.78 ( 78.68)	Acc_5  98.83 ( 98.76)
Test: [39/40]	Time  0.532 ( 2.294)	Loss 0.8227 (0.9475)	Adv_Loss 1.2295 (1.4203)	Acc_1  81.25 ( 75.09)	Acc_5 100.00 ( 98.42)	Adv-Acc_1  43.75 ( 47.90)	Adv-Acc_5 100.00 ( 92.16)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.03455
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [16][  0/196]	Time  3.441 ( 3.441)	Data  0.000 ( 0.000)	Loss 1.1590 (1.1590)	Acc_1  79.69 ( 79.69)	Acc_5  99.22 ( 99.22)
Epoch: [16][100/196]	Time  3.676 ( 3.675)	Data  0.000 ( 0.000)	Loss 1.2005 (1.2137)	Acc_1  81.25 ( 78.94)	Acc_5  99.22 ( 98.80)
Test: [39/40]	Time  0.532 ( 2.293)	Loss 0.7772 (0.9063)	Adv_Loss 1.1930 (1.3992)	Acc_1  87.50 ( 76.36)	Acc_5 100.00 ( 98.52)	Adv-Acc_1  50.00 ( 48.54)	Adv-Acc_5 100.00 ( 92.21)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.02871
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [17][  0/196]	Time  3.476 ( 3.476)	Data  0.000 ( 0.000)	Loss 1.2037 (1.2037)	Acc_1  79.69 ( 79.69)	Acc_5  99.22 ( 99.22)
Epoch: [17][100/196]	Time  3.672 ( 3.675)	Data  0.000 ( 0.000)	Loss 1.2562 (1.2040)	Acc_1  74.61 ( 79.76)	Acc_5  97.27 ( 98.97)
Test: [39/40]	Time  0.529 ( 2.293)	Loss 0.7687 (0.9229)	Adv_Loss 1.1700 (1.4050)	Acc_1  87.50 ( 76.56)	Acc_5 100.00 ( 98.46)	Adv-Acc_1  50.00 ( 48.21)	Adv-Acc_5 100.00 ( 92.20)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.02321
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [18][  0/196]	Time  3.440 ( 3.440)	Data  0.000 ( 0.000)	Loss 1.2246 (1.2246)	Acc_1  82.81 ( 82.81)	Acc_5  97.66 ( 97.66)
Epoch: [18][100/196]	Time  3.676 ( 3.676)	Data  0.000 ( 0.000)	Loss 1.1599 (1.2015)	Acc_1  82.81 ( 79.77)	Acc_5  99.22 ( 98.85)
Test: [39/40]	Time  0.533 ( 2.294)	Loss 0.7675 (0.9120)	Adv_Loss 1.1789 (1.3975)	Acc_1  87.50 ( 76.14)	Acc_5 100.00 ( 98.47)	Adv-Acc_1  50.00 ( 48.70)	Adv-Acc_5 100.00 ( 92.08)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.01813
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [19][  0/196]	Time  3.480 ( 3.480)	Data  0.000 ( 0.000)	Loss 1.2094 (1.2094)	Acc_1  80.47 ( 80.47)	Acc_5  98.05 ( 98.05)
Epoch: [19][100/196]	Time  3.673 ( 3.675)	Data  0.000 ( 0.000)	Loss 1.2529 (1.1923)	Acc_1  78.52 ( 80.25)	Acc_5  99.22 ( 98.92)
Test: [39/40]	Time  0.543 ( 2.310)	Loss 0.7568 (0.9089)	Adv_Loss 1.1645 (1.3925)	Acc_1  87.50 ( 76.80)	Acc_5 100.00 ( 98.59)	Adv-Acc_1  62.50 ( 49.10)	Adv-Acc_5 100.00 ( 92.16)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.01355
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [20][  0/196]	Time  3.525 ( 3.525)	Data  0.000 ( 0.000)	Loss 1.1605 (1.1605)	Acc_1  83.59 ( 83.59)	Acc_5  99.61 ( 99.61)
Epoch: [20][100/196]	Time  3.675 ( 3.693)	Data  0.000 ( 0.000)	Loss 1.2432 (1.1869)	Acc_1  79.30 ( 80.63)	Acc_5  98.44 ( 98.82)
Test: [39/40]	Time  0.533 ( 2.296)	Loss 0.7474 (0.9000)	Adv_Loss 1.1736 (1.3899)	Acc_1  87.50 ( 76.80)	Acc_5 100.00 ( 98.58)	Adv-Acc_1  50.00 ( 48.79)	Adv-Acc_5 100.00 ( 92.55)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00955
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [21][  0/196]	Time  3.441 ( 3.441)	Data  0.000 ( 0.000)	Loss 1.1087 (1.1087)	Acc_1  83.20 ( 83.20)	Acc_5 100.00 (100.00)
Epoch: [21][100/196]	Time  3.677 ( 3.678)	Data  0.000 ( 0.000)	Loss 1.1017 (1.1794)	Acc_1  86.72 ( 80.72)	Acc_5  99.22 ( 98.99)
Test: [39/40]	Time  0.537 ( 2.296)	Loss 0.7425 (0.9222)	Adv_Loss 1.1366 (1.3942)	Acc_1  87.50 ( 76.68)	Acc_5 100.00 ( 98.60)	Adv-Acc_1  62.50 ( 48.97)	Adv-Acc_5 100.00 ( 92.24)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00618
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [22][  0/196]	Time  3.495 ( 3.495)	Data  0.000 ( 0.000)	Loss 1.1776 (1.1776)	Acc_1  80.86 ( 80.86)	Acc_5  99.22 ( 99.22)
Epoch: [22][100/196]	Time  3.680 ( 3.679)	Data  0.000 ( 0.000)	Loss 1.1787 (1.1781)	Acc_1  80.47 ( 80.91)	Acc_5  98.44 ( 98.94)
Test: [39/40]	Time  0.535 ( 2.292)	Loss 0.7562 (0.9061)	Adv_Loss 1.1645 (1.3888)	Acc_1  87.50 ( 76.88)	Acc_5 100.00 ( 98.59)	Adv-Acc_1  56.25 ( 48.92)	Adv-Acc_5 100.00 ( 92.46)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00351
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [23][  0/196]	Time  3.450 ( 3.450)	Data  0.000 ( 0.000)	Loss 1.1714 (1.1714)	Acc_1  79.69 ( 79.69)	Acc_5  98.83 ( 98.83)
Epoch: [23][100/196]	Time  3.674 ( 3.674)	Data  0.000 ( 0.000)	Loss 1.1715 (1.1803)	Acc_1  81.25 ( 80.68)	Acc_5  98.83 ( 99.01)
Test: [39/40]	Time  0.530 ( 2.293)	Loss 0.7408 (0.9006)	Adv_Loss 1.1401 (1.3861)	Acc_1  87.50 ( 76.83)	Acc_5 100.00 ( 98.55)	Adv-Acc_1  50.00 ( 48.66)	Adv-Acc_5 100.00 ( 92.48)
 ->->->->->->->->->-> One epoch with Adversarial training (TRADES) <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00157
Training images range: [tensor(0., device='cuda:0'), tensor(1., device='cuda:0')]
Epoch: [24][  0/196]	Time  3.481 ( 3.481)	Data  0.000 ( 0.000)	Loss 1.1376 (1.1376)	Acc_1  86.33 ( 86.33)	Acc_5  99.22 ( 99.22)
Epoch: [24][100/196]	Time  3.678 ( 3.677)	Data  0.000 ( 0.000)	Loss 1.1599 (1.1717)	Acc_1  81.64 ( 81.25)	Acc_5  98.83 ( 99.04)
Test: [39/40]	Time  0.530 ( 2.293)	Loss 0.7491 (0.9190)	Adv_Loss 1.1413 (1.3926)	Acc_1  87.50 ( 76.93)	Acc_5 100.00 ( 98.60)	Adv-Acc_1  56.25 ( 49.00)	Adv-Acc_5 100.00 ( 92.24)
conv1 SubnetConv(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer1.0.conv1 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer1.0.conv2 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer1.1.conv1 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer1.1.conv2 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer2.0.conv1 SubnetConv(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 0.0
layer2.0.conv2 SubnetConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer2.0.shortcut.0 SubnetConv(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) 0.0
layer2.1.conv1 SubnetConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer2.1.conv2 SubnetConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer3.0.conv1 SubnetConv(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 0.0
layer3.0.conv2 SubnetConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer3.0.shortcut.0 SubnetConv(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) 0.0
layer3.1.conv1 SubnetConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer3.1.conv2 SubnetConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer4.0.conv1 SubnetConv(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 0.0
layer4.0.conv2 SubnetConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer4.0.shortcut.0 SubnetConv(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) 0.0
layer4.1.conv1 SubnetConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
layer4.1.conv2 SubnetConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 0.0
linear SubnetLinear(in_features=512, out_features=10, bias=True) 0.0
=> Reading YAML config from configs/configs.yml
#################### Pruning network ####################
===>>  gradient for weights: None  | training importance scores only
Initialization relevance score with None initialization
Files already downloaded and verified
Files already downloaded and verified
Traing loader: 50000 images, Test loader: 10000 images
Initialization relevance score proportional to weight magnitudes (OVERWRITING SOURCE NET SCORES)
Test: [39/40]	Time  0.547 ( 2.308)	Loss 2.6271 (2.5757)	Adv_Loss 2.7036 (2.6466)	Acc_1  18.75 ( 12.85)	Acc_5  56.25 ( 53.99)	Adv-Acc_1   6.25 (  5.19)	Adv-Acc_5  56.25 ( 51.57)
variable = conv1.weight, Gradient requires_grad = False
variable = conv1.popup_scores, Gradient requires_grad = True
variable = bn1.weight, Gradient requires_grad = True
variable = bn1.bias, Gradient requires_grad = True
variable = layer1.0.conv1.weight, Gradient requires_grad = False
variable = layer1.0.conv1.popup_scores, Gradient requires_grad = True
variable = layer1.0.bn1.weight, Gradient requires_grad = True
variable = layer1.0.bn1.bias, Gradient requires_grad = True
variable = layer1.0.conv2.weight, Gradient requires_grad = False
variable = layer1.0.conv2.popup_scores, Gradient requires_grad = True
variable = layer1.0.bn2.weight, Gradient requires_grad = True
variable = layer1.0.bn2.bias, Gradient requires_grad = True
variable = layer1.1.conv1.weight, Gradient requires_grad = False
variable = layer1.1.conv1.popup_scores, Gradient requires_grad = True
variable = layer1.1.bn1.weight, Gradient requires_grad = True
variable = layer1.1.bn1.bias, Gradient requires_grad = True
variable = layer1.1.conv2.weight, Gradient requires_grad = False
variable = layer1.1.conv2.popup_scores, Gradient requires_grad = True
variable = layer1.1.bn2.weight, Gradient requires_grad = True
variable = layer1.1.bn2.bias, Gradient requires_grad = True
variable = layer2.0.conv1.weight, Gradient requires_grad = False
variable = layer2.0.conv1.popup_scores, Gradient requires_grad = True
variable = layer2.0.bn1.weight, Gradient requires_grad = True
variable = layer2.0.bn1.bias, Gradient requires_grad = True
variable = layer2.0.conv2.weight, Gradient requires_grad = False
variable = layer2.0.conv2.popup_scores, Gradient requires_grad = True
variable = layer2.0.bn2.weight, Gradient requires_grad = True
variable = layer2.0.bn2.bias, Gradient requires_grad = True
variable = layer2.0.shortcut.0.weight, Gradient requires_grad = False
variable = layer2.0.shortcut.0.popup_scores, Gradient requires_grad = True
variable = layer2.0.shortcut.1.weight, Gradient requires_grad = True
variable = layer2.0.shortcut.1.bias, Gradient requires_grad = True
variable = layer2.1.conv1.weight, Gradient requires_grad = False
variable = layer2.1.conv1.popup_scores, Gradient requires_grad = True
variable = layer2.1.bn1.weight, Gradient requires_grad = True
variable = layer2.1.bn1.bias, Gradient requires_grad = True
variable = layer2.1.conv2.weight, Gradient requires_grad = False
variable = layer2.1.conv2.popup_scores, Gradient requires_grad = True
variable = layer2.1.bn2.weight, Gradient requires_grad = True
variable = layer2.1.bn2.bias, Gradient requires_grad = True
variable = layer3.0.conv1.weight, Gradient requires_grad = False
variable = layer3.0.conv1.popup_scores, Gradient requires_grad = True
variable = layer3.0.bn1.weight, Gradient requires_grad = True
variable = layer3.0.bn1.bias, Gradient requires_grad = True
variable = layer3.0.conv2.weight, Gradient requires_grad = False
variable = layer3.0.conv2.popup_scores, Gradient requires_grad = True
variable = layer3.0.bn2.weight, Gradient requires_grad = True
variable = layer3.0.bn2.bias, Gradient requires_grad = True
variable = layer3.0.shortcut.0.weight, Gradient requires_grad = False
variable = layer3.0.shortcut.0.popup_scores, Gradient requires_grad = True
variable = layer3.0.shortcut.1.weight, Gradient requires_grad = True
variable = layer3.0.shortcut.1.bias, Gradient requires_grad = True
variable = layer3.1.conv1.weight, Gradient requires_grad = False
variable = layer3.1.conv1.popup_scores, Gradient requires_grad = True
variable = layer3.1.bn1.weight, Gradient requires_grad = True
variable = layer3.1.bn1.bias, Gradient requires_grad = True
variable = layer3.1.conv2.weight, Gradient requires_grad = False
variable = layer3.1.conv2.popup_scores, Gradient requires_grad = True
variable = layer3.1.bn2.weight, Gradient requires_grad = True
variable = layer3.1.bn2.bias, Gradient requires_grad = True
variable = layer4.0.conv1.weight, Gradient requires_grad = False
variable = layer4.0.conv1.popup_scores, Gradient requires_grad = True
variable = layer4.0.bn1.weight, Gradient requires_grad = True
variable = layer4.0.bn1.bias, Gradient requires_grad = True
variable = layer4.0.conv2.weight, Gradient requires_grad = False
variable = layer4.0.conv2.popup_scores, Gradient requires_grad = True
variable = layer4.0.bn2.weight, Gradient requires_grad = True
variable = layer4.0.bn2.bias, Gradient requires_grad = True
variable = layer4.0.shortcut.0.weight, Gradient requires_grad = False
variable = layer4.0.shortcut.0.popup_scores, Gradient requires_grad = True
variable = layer4.0.shortcut.1.weight, Gradient requires_grad = True
variable = layer4.0.shortcut.1.bias, Gradient requires_grad = True
variable = layer4.1.conv1.weight, Gradient requires_grad = False
variable = layer4.1.conv1.popup_scores, Gradient requires_grad = True
variable = layer4.1.bn1.weight, Gradient requires_grad = True
variable = layer4.1.bn1.bias, Gradient requires_grad = True
variable = layer4.1.conv2.weight, Gradient requires_grad = False
variable = layer4.1.conv2.popup_scores, Gradient requires_grad = True
variable = layer4.1.bn2.weight, Gradient requires_grad = True
variable = layer4.1.bn2.bias, Gradient requires_grad = True
variable = linear.weight, Gradient requires_grad = False
variable = linear.bias, Gradient requires_grad = False
variable = linear.popup_scores, Gradient requires_grad = True
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09961
Pixel range for training images : [0.0, 1.0]
Epoch: [0][  0/196]	Time  0.227 ( 0.227)	Data  0.000 ( 0.000)	Loss 1.6699 (1.6699)	Acc_1  60.55 ( 60.55)	Acc_5  95.70 ( 95.70)
Epoch: [0][100/196]	Time  0.214 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.4940 (0.7860)	Acc_1  84.77 ( 76.53)	Acc_5  99.22 ( 98.57)
Test: [39/40]	Time  0.536 ( 2.297)	Loss 0.2888 (0.5080)	Adv_Loss 7.1733 (7.9881)	Acc_1  87.50 ( 82.10)	Acc_5 100.00 ( 99.30)	Adv-Acc_1   0.00 (  1.09)	Adv-Acc_5  75.00 ( 70.64)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.10000
Pixel range for training images : [0.0, 1.0]
Epoch: [1][  0/196]	Time  0.251 ( 0.251)	Data  0.000 ( 0.000)	Loss 0.4794 (0.4794)	Acc_1  83.98 ( 83.98)	Acc_5  98.83 ( 98.83)
Epoch: [1][100/196]	Time  0.219 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.3611 (0.4218)	Acc_1  88.67 ( 85.75)	Acc_5  99.61 ( 99.53)
Test: [39/40]	Time  0.533 ( 2.297)	Loss 0.3333 (0.4997)	Adv_Loss 9.9259 (10.2689)	Acc_1  93.75 ( 82.88)	Acc_5 100.00 ( 99.40)	Adv-Acc_1   0.00 (  0.47)	Adv-Acc_5  75.00 ( 60.26)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09961
Pixel range for training images : [0.0, 1.0]
Epoch: [2][  0/196]	Time  0.255 ( 0.255)	Data  0.000 ( 0.000)	Loss 0.4031 (0.4031)	Acc_1  87.11 ( 87.11)	Acc_5  99.61 ( 99.61)
Epoch: [2][100/196]	Time  0.219 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.2650 (0.3582)	Acc_1  91.02 ( 87.94)	Acc_5  99.61 ( 99.62)
Test: [39/40]	Time  0.535 ( 2.299)	Loss 0.4234 (0.4746)	Adv_Loss 13.9316 (13.6796)	Acc_1  87.50 ( 83.98)	Acc_5 100.00 ( 99.36)	Adv-Acc_1   0.00 (  0.04)	Adv-Acc_5  56.25 ( 53.92)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09843
Pixel range for training images : [0.0, 1.0]
Epoch: [3][  0/196]	Time  0.208 ( 0.208)	Data  0.000 ( 0.000)	Loss 0.3104 (0.3104)	Acc_1  88.67 ( 88.67)	Acc_5  99.61 ( 99.61)
Epoch: [3][100/196]	Time  0.215 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.2733 (0.3143)	Acc_1  90.23 ( 89.14)	Acc_5 100.00 ( 99.70)
Test: [39/40]	Time  0.537 ( 2.299)	Loss 0.3216 (0.4311)	Adv_Loss 11.8845 (13.0371)	Acc_1  81.25 ( 84.97)	Acc_5 100.00 ( 99.49)	Adv-Acc_1   6.25 (  0.33)	Adv-Acc_5  68.75 ( 58.88)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09649
Pixel range for training images : [0.0, 1.0]
Epoch: [4][  0/196]	Time  0.255 ( 0.255)	Data  0.000 ( 0.000)	Loss 0.3298 (0.3298)	Acc_1  87.89 ( 87.89)	Acc_5 100.00 (100.00)
Epoch: [4][100/196]	Time  0.213 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.2114 (0.2810)	Acc_1  91.80 ( 90.10)	Acc_5 100.00 ( 99.86)
Test: [39/40]	Time  0.535 ( 2.299)	Loss 0.2201 (0.4524)	Adv_Loss 15.4240 (15.6345)	Acc_1  93.75 ( 84.92)	Acc_5 100.00 ( 99.42)	Adv-Acc_1   0.00 (  0.05)	Adv-Acc_5  56.25 ( 48.50)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09382
Pixel range for training images : [0.0, 1.0]
Epoch: [5][  0/196]	Time  0.211 ( 0.211)	Data  0.000 ( 0.000)	Loss 0.2912 (0.2912)	Acc_1  88.67 ( 88.67)	Acc_5  99.61 ( 99.61)
Epoch: [5][100/196]	Time  0.213 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.3024 (0.2531)	Acc_1  89.45 ( 91.41)	Acc_5 100.00 ( 99.86)
Test: [39/40]	Time  0.536 ( 2.299)	Loss 0.4324 (0.3999)	Adv_Loss 15.8901 (15.2348)	Acc_1  87.50 ( 86.67)	Acc_5 100.00 ( 99.38)	Adv-Acc_1   0.00 (  0.10)	Adv-Acc_5  50.00 ( 48.31)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.09045
Pixel range for training images : [0.0, 1.0]
Epoch: [6][  0/196]	Time  0.254 ( 0.254)	Data  0.000 ( 0.000)	Loss 0.2336 (0.2336)	Acc_1  92.19 ( 92.19)	Acc_5 100.00 (100.00)
Epoch: [6][100/196]	Time  0.217 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.2806 (0.2363)	Acc_1  89.45 ( 91.86)	Acc_5  99.61 ( 99.87)
Test: [39/40]	Time  0.538 ( 2.300)	Loss 0.1779 (0.3686)	Adv_Loss 16.5426 (15.7879)	Acc_1  93.75 ( 87.48)	Acc_5 100.00 ( 99.64)	Adv-Acc_1   0.00 (  0.10)	Adv-Acc_5  56.25 ( 50.71)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.08645
Pixel range for training images : [0.0, 1.0]
Epoch: [7][  0/196]	Time  0.211 ( 0.211)	Data  0.000 ( 0.000)	Loss 0.1866 (0.1866)	Acc_1  93.75 ( 93.75)	Acc_5 100.00 (100.00)
Epoch: [7][100/196]	Time  0.218 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.2092 (0.2136)	Acc_1  93.75 ( 92.54)	Acc_5  99.22 ( 99.89)
Test: [39/40]	Time  0.535 ( 2.299)	Loss 0.1790 (0.3970)	Adv_Loss 17.2177 (16.7721)	Acc_1  93.75 ( 86.63)	Acc_5 100.00 ( 99.58)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  50.00 ( 43.02)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.08187
Pixel range for training images : [0.0, 1.0]
Epoch: [8][  0/196]	Time  0.247 ( 0.247)	Data  0.000 ( 0.000)	Loss 0.1969 (0.1969)	Acc_1  91.80 ( 91.80)	Acc_5 100.00 (100.00)
Epoch: [8][100/196]	Time  0.218 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.1808 (0.1955)	Acc_1  94.14 ( 93.29)	Acc_5 100.00 ( 99.88)
Test: [39/40]	Time  0.535 ( 2.300)	Loss 0.1238 (0.3481)	Adv_Loss 18.1858 (18.2517)	Acc_1  93.75 ( 88.40)	Acc_5 100.00 ( 99.64)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  50.00 ( 47.11)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.07679
Pixel range for training images : [0.0, 1.0]
Epoch: [9][  0/196]	Time  0.209 ( 0.209)	Data  0.000 ( 0.000)	Loss 0.1325 (0.1325)	Acc_1  95.31 ( 95.31)	Acc_5 100.00 (100.00)
Epoch: [9][100/196]	Time  0.214 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.2332 (0.1847)	Acc_1  94.14 ( 93.71)	Acc_5  99.61 ( 99.95)
Test: [39/40]	Time  0.536 ( 2.299)	Loss 0.0601 (0.3658)	Adv_Loss 16.5144 (17.2956)	Acc_1 100.00 ( 87.65)	Acc_5 100.00 ( 99.60)	Adv-Acc_1   0.00 (  0.00)	Adv-Acc_5  50.00 ( 40.98)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.07129
Pixel range for training images : [0.0, 1.0]
Epoch: [10][  0/196]	Time  0.253 ( 0.253)	Data  0.000 ( 0.000)	Loss 0.1697 (0.1697)	Acc_1  95.31 ( 95.31)	Acc_5  99.61 ( 99.61)
Epoch: [10][100/196]	Time  0.214 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.1759 (0.1660)	Acc_1  93.36 ( 94.37)	Acc_5 100.00 ( 99.94)
Test: [39/40]	Time  0.537 ( 2.299)	Loss 0.3828 (0.3322)	Adv_Loss 19.8475 (19.2404)	Acc_1  87.50 ( 88.82)	Acc_5 100.00 ( 99.63)	Adv-Acc_1   0.00 (  0.02)	Adv-Acc_5  37.50 ( 38.75)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.06545
Pixel range for training images : [0.0, 1.0]
Epoch: [11][  0/196]	Time  0.258 ( 0.258)	Data  0.000 ( 0.000)	Loss 0.1013 (0.1013)	Acc_1  97.27 ( 97.27)	Acc_5 100.00 (100.00)
Epoch: [11][100/196]	Time  0.218 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.2076 (0.1485)	Acc_1  93.36 ( 94.91)	Acc_5 100.00 ( 99.97)
Test: [39/40]	Time  0.535 ( 2.300)	Loss 0.1086 (0.3493)	Adv_Loss 18.7184 (18.5914)	Acc_1  93.75 ( 88.94)	Acc_5 100.00 ( 99.64)	Adv-Acc_1   0.00 (  0.05)	Adv-Acc_5  50.00 ( 39.22)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.05937
Pixel range for training images : [0.0, 1.0]
Epoch: [12][  0/196]	Time  0.213 ( 0.213)	Data  0.000 ( 0.000)	Loss 0.1503 (0.1503)	Acc_1  94.92 ( 94.92)	Acc_5 100.00 (100.00)
Epoch: [12][100/196]	Time  0.218 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.1184 (0.1360)	Acc_1  95.31 ( 95.50)	Acc_5 100.00 ( 99.96)
Test: [39/40]	Time  0.560 ( 2.300)	Loss 0.2855 (0.3218)	Adv_Loss 20.2470 (20.1337)	Acc_1  93.75 ( 89.67)	Acc_5 100.00 ( 99.57)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  31.25 ( 29.10)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.05314
Pixel range for training images : [0.0, 1.0]
Epoch: [13][  0/196]	Time  0.319 ( 0.319)	Data  0.000 ( 0.000)	Loss 0.1406 (0.1406)	Acc_1  93.75 ( 93.75)	Acc_5 100.00 (100.00)
Epoch: [13][100/196]	Time  0.214 ( 0.220)	Data  0.000 ( 0.000)	Loss 0.1775 (0.1205)	Acc_1  94.14 ( 96.00)	Acc_5 100.00 ( 99.98)
Test: [39/40]	Time  0.561 ( 2.315)	Loss 0.2205 (0.3183)	Adv_Loss 19.4844 (19.9074)	Acc_1  93.75 ( 89.81)	Acc_5 100.00 ( 99.67)	Adv-Acc_1   0.00 (  0.02)	Adv-Acc_5  25.00 ( 29.87)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.04686
Pixel range for training images : [0.0, 1.0]
Epoch: [14][  0/196]	Time  0.227 ( 0.227)	Data  0.000 ( 0.000)	Loss 0.1140 (0.1140)	Acc_1  96.09 ( 96.09)	Acc_5 100.00 (100.00)
Epoch: [14][100/196]	Time  0.213 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.1450 (0.1115)	Acc_1  94.53 ( 96.24)	Acc_5 100.00 ( 99.98)
Test: [39/40]	Time  0.580 ( 2.315)	Loss 0.1465 (0.3166)	Adv_Loss 21.7803 (21.0114)	Acc_1  93.75 ( 89.99)	Acc_5 100.00 ( 99.74)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  37.50 ( 32.08)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.04063
Pixel range for training images : [0.0, 1.0]
Epoch: [15][  0/196]	Time  0.269 ( 0.269)	Data  0.000 ( 0.000)	Loss 0.0674 (0.0674)	Acc_1  97.66 ( 97.66)	Acc_5 100.00 (100.00)
Epoch: [15][100/196]	Time  0.217 ( 0.220)	Data  0.000 ( 0.000)	Loss 0.0700 (0.0971)	Acc_1  98.44 ( 96.81)	Acc_5 100.00 ( 99.99)
Test: [39/40]	Time  0.554 ( 2.313)	Loss 0.3182 (0.3216)	Adv_Loss 21.8524 (21.6345)	Acc_1  93.75 ( 89.92)	Acc_5 100.00 ( 99.71)	Adv-Acc_1   0.00 (  0.04)	Adv-Acc_5  50.00 ( 30.66)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.03455
Pixel range for training images : [0.0, 1.0]
Epoch: [16][  0/196]	Time  0.224 ( 0.224)	Data  0.000 ( 0.000)	Loss 0.1084 (0.1084)	Acc_1  95.70 ( 95.70)	Acc_5  99.61 ( 99.61)
Epoch: [16][100/196]	Time  0.215 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.0960 (0.0862)	Acc_1  96.09 ( 97.12)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.558 ( 2.312)	Loss 0.3663 (0.3393)	Adv_Loss 20.0778 (20.1699)	Acc_1  87.50 ( 89.33)	Acc_5 100.00 ( 99.66)	Adv-Acc_1   0.00 (  0.06)	Adv-Acc_5  43.75 ( 31.79)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.02871
Pixel range for training images : [0.0, 1.0]
Epoch: [17][  0/196]	Time  0.267 ( 0.267)	Data  0.000 ( 0.000)	Loss 0.0600 (0.0600)	Acc_1  99.22 ( 99.22)	Acc_5 100.00 (100.00)
Epoch: [17][100/196]	Time  0.214 ( 0.220)	Data  0.000 ( 0.000)	Loss 0.0564 (0.0761)	Acc_1  98.83 ( 97.66)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.557 ( 2.313)	Loss 0.2292 (0.3138)	Adv_Loss 22.1549 (21.9658)	Acc_1  93.75 ( 90.40)	Acc_5 100.00 ( 99.67)	Adv-Acc_1   0.00 (  0.03)	Adv-Acc_5  37.50 ( 25.44)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.02321
Pixel range for training images : [0.0, 1.0]
Epoch: [18][  0/196]	Time  0.222 ( 0.222)	Data  0.000 ( 0.000)	Loss 0.0616 (0.0616)	Acc_1  98.05 ( 98.05)	Acc_5 100.00 (100.00)
Epoch: [18][100/196]	Time  0.219 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.0442 (0.0661)	Acc_1  98.83 ( 98.00)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.540 ( 2.311)	Loss 0.0583 (0.3087)	Adv_Loss 22.1607 (22.2963)	Acc_1 100.00 ( 90.47)	Acc_5 100.00 ( 99.72)	Adv-Acc_1   0.00 (  0.02)	Adv-Acc_5  37.50 ( 25.27)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.01813
Pixel range for training images : [0.0, 1.0]
Epoch: [19][  0/196]	Time  0.261 ( 0.261)	Data  0.000 ( 0.000)	Loss 0.0501 (0.0501)	Acc_1  98.44 ( 98.44)	Acc_5 100.00 (100.00)
Epoch: [19][100/196]	Time  0.220 ( 0.220)	Data  0.000 ( 0.000)	Loss 0.0509 (0.0582)	Acc_1  98.05 ( 98.36)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.557 ( 2.313)	Loss 0.2216 (0.2833)	Adv_Loss 22.4859 (22.1009)	Acc_1  93.75 ( 91.44)	Acc_5 100.00 ( 99.78)	Adv-Acc_1   0.00 (  0.03)	Adv-Acc_5  37.50 ( 23.77)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.01355
Pixel range for training images : [0.0, 1.0]
Epoch: [20][  0/196]	Time  0.278 ( 0.278)	Data  0.000 ( 0.000)	Loss 0.0730 (0.0730)	Acc_1  98.44 ( 98.44)	Acc_5 100.00 (100.00)
Epoch: [20][100/196]	Time  0.219 ( 0.220)	Data  0.000 ( 0.000)	Loss 0.0702 (0.0539)	Acc_1  97.66 ( 98.48)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.566 ( 2.314)	Loss 0.3035 (0.2830)	Adv_Loss 23.0854 (22.6539)	Acc_1  93.75 ( 91.24)	Acc_5 100.00 ( 99.75)	Adv-Acc_1   0.00 (  0.04)	Adv-Acc_5  31.25 ( 22.17)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00955
Pixel range for training images : [0.0, 1.0]
Epoch: [21][  0/196]	Time  0.227 ( 0.227)	Data  0.000 ( 0.000)	Loss 0.0765 (0.0765)	Acc_1  98.44 ( 98.44)	Acc_5 100.00 (100.00)
Epoch: [21][100/196]	Time  0.219 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.0461 (0.0512)	Acc_1  99.61 ( 98.55)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.562 ( 2.314)	Loss 0.1682 (0.2832)	Adv_Loss 23.1332 (22.4694)	Acc_1  93.75 ( 91.53)	Acc_5 100.00 ( 99.73)	Adv-Acc_1   0.00 (  0.04)	Adv-Acc_5  31.25 ( 22.44)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00618
Pixel range for training images : [0.0, 1.0]
Epoch: [22][  0/196]	Time  0.274 ( 0.274)	Data  0.000 ( 0.000)	Loss 0.0372 (0.0372)	Acc_1  99.61 ( 99.61)	Acc_5 100.00 (100.00)
Epoch: [22][100/196]	Time  0.216 ( 0.220)	Data  0.000 ( 0.000)	Loss 0.0439 (0.0451)	Acc_1  98.83 ( 98.84)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.539 ( 2.312)	Loss 0.1471 (0.2925)	Adv_Loss 22.3549 (22.5493)	Acc_1  93.75 ( 91.01)	Acc_5 100.00 ( 99.75)	Adv-Acc_1   0.00 (  0.03)	Adv-Acc_5  31.25 ( 21.25)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00351
Pixel range for training images : [0.0, 1.0]
Epoch: [23][  0/196]	Time  0.227 ( 0.227)	Data  0.000 ( 0.000)	Loss 0.0399 (0.0399)	Acc_1  99.22 ( 99.22)	Acc_5 100.00 (100.00)
Epoch: [23][100/196]	Time  0.212 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.0339 (0.0401)	Acc_1  98.83 ( 98.98)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.555 ( 2.310)	Loss 0.1661 (0.2797)	Adv_Loss 22.5949 (22.9102)	Acc_1  93.75 ( 91.56)	Acc_5 100.00 ( 99.74)	Adv-Acc_1   0.00 (  0.02)	Adv-Acc_5  37.50 ( 18.44)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00157
Pixel range for training images : [0.0, 1.0]
Epoch: [24][  0/196]	Time  0.319 ( 0.319)	Data  0.000 ( 0.000)	Loss 0.0476 (0.0476)	Acc_1  98.83 ( 98.83)	Acc_5 100.00 (100.00)
Epoch: [24][100/196]	Time  0.219 ( 0.220)	Data  0.000 ( 0.000)	Loss 0.0468 (0.0412)	Acc_1  98.44 ( 98.98)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.551 ( 2.313)	Loss 0.1463 (0.2755)	Adv_Loss 23.1746 (22.5572)	Acc_1  93.75 ( 91.75)	Acc_5 100.00 ( 99.68)	Adv-Acc_1   0.00 (  0.03)	Adv-Acc_5  25.00 ( 19.49)
conv1 SubnetConv(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.98842592592592
layer1.0.conv1 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99837239583333
layer1.0.conv2 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99837239583333
layer1.1.conv1 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99837239583333
layer1.1.conv2 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99837239583333
layer2.0.conv1 SubnetConv(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 89.99972873263889
layer2.0.conv2 SubnetConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99972873263889
layer2.0.shortcut.0 SubnetConv(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) 89.990234375
layer2.1.conv1 SubnetConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99972873263889
layer2.1.conv2 SubnetConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99972873263889
layer3.0.conv1 SubnetConv(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 89.99972873263889
layer3.0.conv2 SubnetConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99989827473958
layer3.0.shortcut.0 SubnetConv(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) 89.9993896484375
layer3.1.conv1 SubnetConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99989827473958
layer3.1.conv2 SubnetConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99989827473958
layer4.0.conv1 SubnetConv(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 89.99998304578993
layer4.0.conv2 SubnetConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99998304578993
layer4.0.shortcut.0 SubnetConv(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) 89.9993896484375
layer4.1.conv1 SubnetConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99998304578993
layer4.1.conv2 SubnetConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99998304578993
linear SubnetLinear(in_features=512, out_features=10, bias=True) 90.0
=> Reading YAML config from configs/configs.yml
#################### Fine-tuning network ####################
===>>  gradient for importance_scores: None  | fine-tuning important weigths only
Initialization relevance score with None initialization
Files already downloaded and verified
Files already downloaded and verified
Traing loader: 50000 images, Test loader: 10000 images
Test: [39/40]	Time  0.558 ( 2.317)	Loss 0.1463 (0.2755)	Adv_Loss 22.4527 (22.5584)	Acc_1  93.75 ( 91.75)	Acc_5 100.00 ( 99.68)	Adv-Acc_1   0.00 (  0.02)	Adv-Acc_5  31.25 ( 19.81)
variable = conv1.weight, Gradient requires_grad = True
variable = conv1.popup_scores, Gradient requires_grad = False
variable = bn1.weight, Gradient requires_grad = True
variable = bn1.bias, Gradient requires_grad = True
variable = layer1.0.conv1.weight, Gradient requires_grad = True
variable = layer1.0.conv1.popup_scores, Gradient requires_grad = False
variable = layer1.0.bn1.weight, Gradient requires_grad = True
variable = layer1.0.bn1.bias, Gradient requires_grad = True
variable = layer1.0.conv2.weight, Gradient requires_grad = True
variable = layer1.0.conv2.popup_scores, Gradient requires_grad = False
variable = layer1.0.bn2.weight, Gradient requires_grad = True
variable = layer1.0.bn2.bias, Gradient requires_grad = True
variable = layer1.1.conv1.weight, Gradient requires_grad = True
variable = layer1.1.conv1.popup_scores, Gradient requires_grad = False
variable = layer1.1.bn1.weight, Gradient requires_grad = True
variable = layer1.1.bn1.bias, Gradient requires_grad = True
variable = layer1.1.conv2.weight, Gradient requires_grad = True
variable = layer1.1.conv2.popup_scores, Gradient requires_grad = False
variable = layer1.1.bn2.weight, Gradient requires_grad = True
variable = layer1.1.bn2.bias, Gradient requires_grad = True
variable = layer2.0.conv1.weight, Gradient requires_grad = True
variable = layer2.0.conv1.popup_scores, Gradient requires_grad = False
variable = layer2.0.bn1.weight, Gradient requires_grad = True
variable = layer2.0.bn1.bias, Gradient requires_grad = True
variable = layer2.0.conv2.weight, Gradient requires_grad = True
variable = layer2.0.conv2.popup_scores, Gradient requires_grad = False
variable = layer2.0.bn2.weight, Gradient requires_grad = True
variable = layer2.0.bn2.bias, Gradient requires_grad = True
variable = layer2.0.shortcut.0.weight, Gradient requires_grad = True
variable = layer2.0.shortcut.0.popup_scores, Gradient requires_grad = False
variable = layer2.0.shortcut.1.weight, Gradient requires_grad = True
variable = layer2.0.shortcut.1.bias, Gradient requires_grad = True
variable = layer2.1.conv1.weight, Gradient requires_grad = True
variable = layer2.1.conv1.popup_scores, Gradient requires_grad = False
variable = layer2.1.bn1.weight, Gradient requires_grad = True
variable = layer2.1.bn1.bias, Gradient requires_grad = True
variable = layer2.1.conv2.weight, Gradient requires_grad = True
variable = layer2.1.conv2.popup_scores, Gradient requires_grad = False
variable = layer2.1.bn2.weight, Gradient requires_grad = True
variable = layer2.1.bn2.bias, Gradient requires_grad = True
variable = layer3.0.conv1.weight, Gradient requires_grad = True
variable = layer3.0.conv1.popup_scores, Gradient requires_grad = False
variable = layer3.0.bn1.weight, Gradient requires_grad = True
variable = layer3.0.bn1.bias, Gradient requires_grad = True
variable = layer3.0.conv2.weight, Gradient requires_grad = True
variable = layer3.0.conv2.popup_scores, Gradient requires_grad = False
variable = layer3.0.bn2.weight, Gradient requires_grad = True
variable = layer3.0.bn2.bias, Gradient requires_grad = True
variable = layer3.0.shortcut.0.weight, Gradient requires_grad = True
variable = layer3.0.shortcut.0.popup_scores, Gradient requires_grad = False
variable = layer3.0.shortcut.1.weight, Gradient requires_grad = True
variable = layer3.0.shortcut.1.bias, Gradient requires_grad = True
variable = layer3.1.conv1.weight, Gradient requires_grad = True
variable = layer3.1.conv1.popup_scores, Gradient requires_grad = False
variable = layer3.1.bn1.weight, Gradient requires_grad = True
variable = layer3.1.bn1.bias, Gradient requires_grad = True
variable = layer3.1.conv2.weight, Gradient requires_grad = True
variable = layer3.1.conv2.popup_scores, Gradient requires_grad = False
variable = layer3.1.bn2.weight, Gradient requires_grad = True
variable = layer3.1.bn2.bias, Gradient requires_grad = True
variable = layer4.0.conv1.weight, Gradient requires_grad = True
variable = layer4.0.conv1.popup_scores, Gradient requires_grad = False
variable = layer4.0.bn1.weight, Gradient requires_grad = True
variable = layer4.0.bn1.bias, Gradient requires_grad = True
variable = layer4.0.conv2.weight, Gradient requires_grad = True
variable = layer4.0.conv2.popup_scores, Gradient requires_grad = False
variable = layer4.0.bn2.weight, Gradient requires_grad = True
variable = layer4.0.bn2.bias, Gradient requires_grad = True
variable = layer4.0.shortcut.0.weight, Gradient requires_grad = True
variable = layer4.0.shortcut.0.popup_scores, Gradient requires_grad = False
variable = layer4.0.shortcut.1.weight, Gradient requires_grad = True
variable = layer4.0.shortcut.1.bias, Gradient requires_grad = True
variable = layer4.1.conv1.weight, Gradient requires_grad = True
variable = layer4.1.conv1.popup_scores, Gradient requires_grad = False
variable = layer4.1.bn1.weight, Gradient requires_grad = True
variable = layer4.1.bn1.bias, Gradient requires_grad = True
variable = layer4.1.conv2.weight, Gradient requires_grad = True
variable = layer4.1.conv2.popup_scores, Gradient requires_grad = False
variable = layer4.1.bn2.weight, Gradient requires_grad = True
variable = layer4.1.bn2.bias, Gradient requires_grad = True
variable = linear.weight, Gradient requires_grad = True
variable = linear.bias, Gradient requires_grad = True
variable = linear.popup_scores, Gradient requires_grad = False
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00996
Pixel range for training images : [0.0, 1.0]
Epoch: [0][  0/196]	Time  0.234 ( 0.234)	Data  0.000 ( 0.000)	Loss 0.0755 (0.0755)	Acc_1  97.66 ( 97.66)	Acc_5 100.00 (100.00)
Epoch: [0][100/196]	Time  0.218 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.0305 (0.0372)	Acc_1  99.22 ( 99.06)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.529 ( 2.304)	Loss 0.1649 (0.2808)	Adv_Loss 24.2898 (23.7737)	Acc_1  93.75 ( 91.73)	Acc_5 100.00 ( 99.76)	Adv-Acc_1   0.00 (  0.00)	Adv-Acc_5  18.75 ( 19.28)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.01000
Pixel range for training images : [0.0, 1.0]
Epoch: [1][  0/196]	Time  0.293 ( 0.293)	Data  0.000 ( 0.000)	Loss 0.0288 (0.0288)	Acc_1  99.22 ( 99.22)	Acc_5 100.00 (100.00)
Epoch: [1][100/196]	Time  0.217 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.0170 (0.0329)	Acc_1 100.00 ( 99.15)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.544 ( 2.304)	Loss 0.2526 (0.2875)	Adv_Loss 25.5042 (24.9250)	Acc_1  93.75 ( 91.75)	Acc_5 100.00 ( 99.75)	Adv-Acc_1   0.00 (  0.00)	Adv-Acc_5  25.00 ( 20.52)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00996
Pixel range for training images : [0.0, 1.0]
Epoch: [2][  0/196]	Time  0.266 ( 0.266)	Data  0.000 ( 0.000)	Loss 0.0267 (0.0267)	Acc_1  99.61 ( 99.61)	Acc_5 100.00 (100.00)
Epoch: [2][100/196]	Time  0.217 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.0204 (0.0279)	Acc_1 100.00 ( 99.32)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.551 ( 2.308)	Loss 0.1835 (0.2929)	Adv_Loss 25.4052 (25.4928)	Acc_1  93.75 ( 91.84)	Acc_5 100.00 ( 99.72)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  25.00 ( 20.06)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00984
Pixel range for training images : [0.0, 1.0]
Epoch: [3][  0/196]	Time  0.219 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.0277 (0.0277)	Acc_1  99.61 ( 99.61)	Acc_5 100.00 (100.00)
Epoch: [3][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0184 (0.0271)	Acc_1 100.00 ( 99.35)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.525 ( 2.290)	Loss 0.2186 (0.2996)	Adv_Loss 27.1947 (26.6169)	Acc_1  93.75 ( 91.78)	Acc_5 100.00 ( 99.71)	Adv-Acc_1   0.00 (  0.00)	Adv-Acc_5  25.00 ( 19.15)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00965
Pixel range for training images : [0.0, 1.0]
Epoch: [4][  0/196]	Time  0.294 ( 0.294)	Data  0.000 ( 0.000)	Loss 0.0309 (0.0309)	Acc_1  99.61 ( 99.61)	Acc_5 100.00 (100.00)
Epoch: [4][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0191 (0.0250)	Acc_1 100.00 ( 99.40)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.525 ( 2.290)	Loss 0.2018 (0.3047)	Adv_Loss 27.5814 (27.1103)	Acc_1  93.75 ( 91.72)	Acc_5 100.00 ( 99.74)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  25.00 ( 20.01)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00938
Pixel range for training images : [0.0, 1.0]
Epoch: [5][  0/196]	Time  0.211 ( 0.211)	Data  0.000 ( 0.000)	Loss 0.0369 (0.0369)	Acc_1  98.83 ( 98.83)	Acc_5 100.00 (100.00)
Epoch: [5][100/196]	Time  0.214 ( 0.217)	Data  0.000 ( 0.000)	Loss 0.0271 (0.0228)	Acc_1  99.22 ( 99.44)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.526 ( 2.290)	Loss 0.1432 (0.3076)	Adv_Loss 29.0681 (27.7372)	Acc_1  93.75 ( 91.80)	Acc_5 100.00 ( 99.74)	Adv-Acc_1   0.00 (  0.02)	Adv-Acc_5  18.75 ( 20.83)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00905
Pixel range for training images : [0.0, 1.0]
Epoch: [6][  0/196]	Time  0.251 ( 0.251)	Data  0.000 ( 0.000)	Loss 0.0265 (0.0265)	Acc_1  99.22 ( 99.22)	Acc_5 100.00 (100.00)
Epoch: [6][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0139 (0.0215)	Acc_1 100.00 ( 99.41)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.525 ( 2.289)	Loss 0.2040 (0.3142)	Adv_Loss 29.8708 (28.0321)	Acc_1  93.75 ( 91.77)	Acc_5 100.00 ( 99.74)	Adv-Acc_1   0.00 (  0.03)	Adv-Acc_5  25.00 ( 20.98)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00864
Pixel range for training images : [0.0, 1.0]
Epoch: [7][  0/196]	Time  0.215 ( 0.215)	Data  0.000 ( 0.000)	Loss 0.0158 (0.0158)	Acc_1  99.61 ( 99.61)	Acc_5 100.00 (100.00)
Epoch: [7][100/196]	Time  0.216 ( 0.217)	Data  0.000 ( 0.000)	Loss 0.0160 (0.0183)	Acc_1 100.00 ( 99.57)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.525 ( 2.290)	Loss 0.1932 (0.3136)	Adv_Loss 29.6555 (28.5602)	Acc_1  93.75 ( 91.84)	Acc_5 100.00 ( 99.72)	Adv-Acc_1   0.00 (  0.00)	Adv-Acc_5  31.25 ( 20.36)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00819
Pixel range for training images : [0.0, 1.0]
Epoch: [8][  0/196]	Time  0.253 ( 0.253)	Data  0.000 ( 0.000)	Loss 0.0280 (0.0280)	Acc_1  99.22 ( 99.22)	Acc_5 100.00 (100.00)
Epoch: [8][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0105 (0.0173)	Acc_1  99.61 ( 99.58)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.525 ( 2.290)	Loss 0.1588 (0.3159)	Adv_Loss 30.0831 (28.9651)	Acc_1  93.75 ( 91.82)	Acc_5 100.00 ( 99.73)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  25.00 ( 20.40)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00768
Pixel range for training images : [0.0, 1.0]
Epoch: [9][  0/196]	Time  0.219 ( 0.219)	Data  0.000 ( 0.000)	Loss 0.0146 (0.0146)	Acc_1  99.22 ( 99.22)	Acc_5 100.00 (100.00)
Epoch: [9][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0199 (0.0164)	Acc_1  99.61 ( 99.64)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.534 ( 2.293)	Loss 0.1406 (0.3175)	Adv_Loss 28.3018 (29.1188)	Acc_1  93.75 ( 91.87)	Acc_5 100.00 ( 99.73)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  31.25 ( 21.14)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00713
Pixel range for training images : [0.0, 1.0]
Epoch: [10][  0/196]	Time  0.252 ( 0.252)	Data  0.000 ( 0.000)	Loss 0.0218 (0.0218)	Acc_1  99.61 ( 99.61)	Acc_5 100.00 (100.00)
Epoch: [10][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0243 (0.0160)	Acc_1  98.83 ( 99.60)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.528 ( 2.292)	Loss 0.1429 (0.3199)	Adv_Loss 30.6783 (29.4376)	Acc_1  93.75 ( 91.89)	Acc_5 100.00 ( 99.73)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  25.00 ( 21.66)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00655
Pixel range for training images : [0.0, 1.0]
Epoch: [11][  0/196]	Time  0.260 ( 0.260)	Data  0.000 ( 0.000)	Loss 0.0067 (0.0067)	Acc_1 100.00 (100.00)	Acc_5 100.00 (100.00)
Epoch: [11][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0098 (0.0133)	Acc_1 100.00 ( 99.74)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.536 ( 2.293)	Loss 0.1447 (0.3243)	Adv_Loss 31.1064 (29.8228)	Acc_1  93.75 ( 91.88)	Acc_5 100.00 ( 99.73)	Adv-Acc_1   0.00 (  0.00)	Adv-Acc_5  31.25 ( 21.18)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00594
Pixel range for training images : [0.0, 1.0]
Epoch: [12][  0/196]	Time  0.214 ( 0.214)	Data  0.000 ( 0.000)	Loss 0.0088 (0.0088)	Acc_1 100.00 (100.00)	Acc_5 100.00 (100.00)
Epoch: [12][100/196]	Time  0.217 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0060 (0.0125)	Acc_1 100.00 ( 99.80)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.526 ( 2.292)	Loss 0.1479 (0.3259)	Adv_Loss 31.0508 (30.1524)	Acc_1  93.75 ( 91.87)	Acc_5 100.00 ( 99.74)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  25.00 ( 21.08)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00531
Pixel range for training images : [0.0, 1.0]
Epoch: [13][  0/196]	Time  0.260 ( 0.260)	Data  0.000 ( 0.000)	Loss 0.0218 (0.0218)	Acc_1  99.22 ( 99.22)	Acc_5 100.00 (100.00)
Epoch: [13][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0092 (0.0122)	Acc_1 100.00 ( 99.79)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.527 ( 2.291)	Loss 0.1626 (0.3244)	Adv_Loss 31.8859 (30.1528)	Acc_1  93.75 ( 91.87)	Acc_5 100.00 ( 99.73)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  25.00 ( 20.88)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00469
Pixel range for training images : [0.0, 1.0]
Epoch: [14][  0/196]	Time  0.214 ( 0.214)	Data  0.000 ( 0.000)	Loss 0.0046 (0.0046)	Acc_1 100.00 (100.00)	Acc_5 100.00 (100.00)
Epoch: [14][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0149 (0.0116)	Acc_1  99.22 ( 99.79)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.528 ( 2.291)	Loss 0.2093 (0.3261)	Adv_Loss 30.0332 (30.4931)	Acc_1  93.75 ( 91.95)	Acc_5 100.00 ( 99.74)	Adv-Acc_1   0.00 (  0.02)	Adv-Acc_5  25.00 ( 20.81)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00406
Pixel range for training images : [0.0, 1.0]
Epoch: [15][  0/196]	Time  0.256 ( 0.256)	Data  0.000 ( 0.000)	Loss 0.0107 (0.0107)	Acc_1 100.00 (100.00)	Acc_5 100.00 (100.00)
Epoch: [15][100/196]	Time  0.212 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0137 (0.0108)	Acc_1  99.61 ( 99.85)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.528 ( 2.291)	Loss 0.1610 (0.3263)	Adv_Loss 30.0118 (30.5881)	Acc_1  93.75 ( 91.85)	Acc_5 100.00 ( 99.72)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  25.00 ( 20.75)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00345
Pixel range for training images : [0.0, 1.0]
Epoch: [16][  0/196]	Time  0.207 ( 0.207)	Data  0.000 ( 0.000)	Loss 0.0144 (0.0144)	Acc_1 100.00 (100.00)	Acc_5 100.00 (100.00)
Epoch: [16][100/196]	Time  0.216 ( 0.217)	Data  0.000 ( 0.000)	Loss 0.0117 (0.0104)	Acc_1  99.61 ( 99.82)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.523 ( 2.290)	Loss 0.1466 (0.3277)	Adv_Loss 32.0196 (30.7960)	Acc_1  93.75 ( 91.82)	Acc_5 100.00 ( 99.75)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  25.00 ( 20.77)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00287
Pixel range for training images : [0.0, 1.0]
Epoch: [17][  0/196]	Time  0.255 ( 0.255)	Data  0.000 ( 0.000)	Loss 0.0093 (0.0093)	Acc_1 100.00 (100.00)	Acc_5 100.00 (100.00)
Epoch: [17][100/196]	Time  0.215 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0063 (0.0096)	Acc_1 100.00 ( 99.86)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.524 ( 2.288)	Loss 0.0990 (0.3300)	Adv_Loss 32.0275 (30.8007)	Acc_1  93.75 ( 91.83)	Acc_5 100.00 ( 99.74)	Adv-Acc_1   0.00 (  0.03)	Adv-Acc_5  37.50 ( 21.39)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00232
Pixel range for training images : [0.0, 1.0]
Epoch: [18][  0/196]	Time  0.215 ( 0.215)	Data  0.000 ( 0.000)	Loss 0.0110 (0.0110)	Acc_1  99.61 ( 99.61)	Acc_5 100.00 (100.00)
Epoch: [18][100/196]	Time  0.217 ( 0.217)	Data  0.000 ( 0.000)	Loss 0.0031 (0.0100)	Acc_1 100.00 ( 99.85)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.523 ( 2.288)	Loss 0.1434 (0.3298)	Adv_Loss 32.6767 (31.1286)	Acc_1  93.75 ( 91.92)	Acc_5 100.00 ( 99.74)	Adv-Acc_1   0.00 (  0.00)	Adv-Acc_5  31.25 ( 20.69)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00181
Pixel range for training images : [0.0, 1.0]
Epoch: [19][  0/196]	Time  0.249 ( 0.249)	Data  0.000 ( 0.000)	Loss 0.0075 (0.0075)	Acc_1 100.00 (100.00)	Acc_5 100.00 (100.00)
Epoch: [19][100/196]	Time  0.215 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0069 (0.0098)	Acc_1 100.00 ( 99.88)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.532 ( 2.292)	Loss 0.1463 (0.3292)	Adv_Loss 32.2892 (30.9311)	Acc_1  93.75 ( 92.07)	Acc_5 100.00 ( 99.74)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  25.00 ( 20.91)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00136
Pixel range for training images : [0.0, 1.0]
Epoch: [20][  0/196]	Time  0.262 ( 0.262)	Data  0.000 ( 0.000)	Loss 0.0130 (0.0130)	Acc_1  99.61 ( 99.61)	Acc_5 100.00 (100.00)
Epoch: [20][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0114 (0.0113)	Acc_1  99.61 ( 99.83)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.526 ( 2.292)	Loss 0.1500 (0.3313)	Adv_Loss 30.9987 (31.0539)	Acc_1  93.75 ( 91.92)	Acc_5 100.00 ( 99.72)	Adv-Acc_1   0.00 (  0.02)	Adv-Acc_5  25.00 ( 21.40)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00095
Pixel range for training images : [0.0, 1.0]
Epoch: [21][  0/196]	Time  0.217 ( 0.217)	Data  0.000 ( 0.000)	Loss 0.0162 (0.0162)	Acc_1  99.61 ( 99.61)	Acc_5 100.00 (100.00)
Epoch: [21][100/196]	Time  0.216 ( 0.217)	Data  0.000 ( 0.000)	Loss 0.0215 (0.0129)	Acc_1  99.61 ( 99.78)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.527 ( 2.291)	Loss 0.1358 (0.3334)	Adv_Loss 32.1754 (31.3744)	Acc_1  93.75 ( 91.87)	Acc_5 100.00 ( 99.77)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  25.00 ( 21.23)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00062
Pixel range for training images : [0.0, 1.0]
Epoch: [22][  0/196]	Time  0.250 ( 0.250)	Data  0.000 ( 0.000)	Loss 0.0132 (0.0132)	Acc_1 100.00 (100.00)	Acc_5 100.00 (100.00)
Epoch: [22][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0145 (0.0139)	Acc_1 100.00 ( 99.73)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.527 ( 2.292)	Loss 0.1072 (0.3324)	Adv_Loss 31.4822 (31.2146)	Acc_1  93.75 ( 91.89)	Acc_5 100.00 ( 99.76)	Adv-Acc_1   0.00 (  0.01)	Adv-Acc_5  31.25 ( 20.89)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00035
Pixel range for training images : [0.0, 1.0]
Epoch: [23][  0/196]	Time  0.208 ( 0.208)	Data  0.000 ( 0.000)	Loss 0.0119 (0.0119)	Acc_1  99.61 ( 99.61)	Acc_5 100.00 (100.00)
Epoch: [23][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0165 (0.0142)	Acc_1  99.61 ( 99.69)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.528 ( 2.291)	Loss 0.1184 (0.3306)	Adv_Loss 31.5584 (31.3096)	Acc_1  93.75 ( 91.93)	Acc_5 100.00 ( 99.72)	Adv-Acc_1   0.00 (  0.02)	Adv-Acc_5  31.25 ( 20.58)
 ->->->->->->->->->-> One epoch with Natural training <-<-<-<-<-<-<-<-<-<-
torch.Size([256, 3, 32, 32]) torch.Size([256]) Batch_size from args: 256 lr: 0.00016
Pixel range for training images : [0.0, 1.0]
Epoch: [24][  0/196]	Time  0.254 ( 0.254)	Data  0.000 ( 0.000)	Loss 0.0186 (0.0186)	Acc_1  99.22 ( 99.22)	Acc_5 100.00 (100.00)
Epoch: [24][100/196]	Time  0.216 ( 0.218)	Data  0.000 ( 0.000)	Loss 0.0257 (0.0186)	Acc_1  99.22 ( 99.50)	Acc_5 100.00 (100.00)
Test: [39/40]	Time  0.528 ( 2.292)	Loss 0.1260 (0.3296)	Adv_Loss 32.1033 (31.0705)	Acc_1  93.75 ( 91.91)	Acc_5 100.00 ( 99.73)	Adv-Acc_1   0.00 (  0.02)	Adv-Acc_5  31.25 ( 20.94)
conv1 SubnetConv(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.98842592592592
layer1.0.conv1 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99837239583333
layer1.0.conv2 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99837239583333
layer1.1.conv1 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99837239583333
layer1.1.conv2 SubnetConv(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99837239583333
layer2.0.conv1 SubnetConv(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 89.99972873263889
layer2.0.conv2 SubnetConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99972873263889
layer2.0.shortcut.0 SubnetConv(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) 89.990234375
layer2.1.conv1 SubnetConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99972873263889
layer2.1.conv2 SubnetConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99972873263889
layer3.0.conv1 SubnetConv(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 89.99972873263889
layer3.0.conv2 SubnetConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99989827473958
layer3.0.shortcut.0 SubnetConv(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) 89.9993896484375
layer3.1.conv1 SubnetConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99989827473958
layer3.1.conv2 SubnetConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99989827473958
layer4.0.conv1 SubnetConv(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) 89.99998304578993
layer4.0.conv2 SubnetConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99998304578993
layer4.0.shortcut.0 SubnetConv(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) 89.9993896484375
layer4.1.conv1 SubnetConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99998304578993
layer4.1.conv2 SubnetConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) 89.99998304578993
linear SubnetLinear(in_features=512, out_features=10, bias=True) 90.0
